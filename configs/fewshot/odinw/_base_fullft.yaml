MODEL:
  META_ARCHITECTURE: "ATSS"
  WEIGHTS: "./checkpoints/dyhead_swint_atss_fpn_2x_ms.pth" # pre-trained on dyhead
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  BACKBONE:
    NAME: "build_retinanet_swint_fpn_dyhead_backbone"
    # FREEZE_AT: 2 # freeze first stage of Swin-T
    FREEZE_AT: -1 # unfreeze all parameters
  SWINT:
    OUT_FEATURES: ["stage3", "stage4", "stage5"]
  FPN:
    IN_FEATURES: ["stage3", "stage4", "stage5"]
  DYHEAD:
    NUM_CONVS: 6
    CHANNELS: 256
  ANCHOR_GENERATOR:
    SIZES: !!python/object/apply:eval ["[[x*2,] for x in [32, 64, 128, 256, 512 ]]"]
    ASPECT_RATIOS: [1.0,]
    OFFSET: 0.5
  ATSS:
    NUM_CONVS: 0
SOLVER:
  IMS_PER_BATCH: 32
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 2.0 # following GLIP, double lr for bias parameters
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.0 # following GLIP, set weight decay as 0.0 for bias parameters
  OPTIMIZER: "ADAMW"
  STEPS: (999998, 999999)
  MAX_ITER: 10000 # maximum iteration: useful for large-size dataset to apply short-training
  # === custom ===
  CHECKPOINT_PERIOD: 1000000 # save only the final checkpoint
  MAX_EPOCH: 200
  WARMUP_ITERS: 0
  EPOCH_ITER: 'epoch'
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 1.0
    NORM_TYPE: 2.0
  USE_AUTOSTEP: True
  STEP_PATIENCE: 3
  # === 
INPUT:
  FORMAT: "RGB"
  # MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN: (480, 560, 640, 720, 800) # GLIP style
VERSION: 2
SEED: 42 # set random seed
TEST:
  EVAL_EPOCH: 1 # eval every n epochs
DATALOADER:
  NUM_WORKERS: 8