_BASE_: "Base-RCNN-FPN.yaml" # based on FasterRCNN + FPN architecture
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHTS: "./checkpoints/swin_tiny_patch4_window7_224_d2.pth"
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  BACKBONE:
    NAME: "build_swint_fpn_backbone"
  SWINT:
    OUT_FEATURES: ["stage2", "stage3", "stage4", "stage5"]
  FPN:
    IN_FEATURES: ["stage2", "stage3", "stage4", "stage5"]
  ROI_HEADS:
    NUM_CLASSES: 80 # no need to add background class
DATASETS:
  TRAIN: ("coco_2017_train",)
  TEST: ("coco_2017_val",)
SOLVER:
  # [dyhead setting]
  IMS_PER_BATCH: 32
  BASE_LR: 0.0001
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.05 # [fix error whten optimize]
  STEPS: (60000, 80000)
  MAX_ITER: 90000 # 24 epoch with 32 batch size
  OPTIMIZER: "ADAMW"
INPUT:
  FORMAT: "RGB"
  # MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN: (480, 560, 640, 720, 800) # GLIP style
VERSION: 2